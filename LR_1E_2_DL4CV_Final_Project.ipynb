{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d67572e2cd3425cad8e5ff88fb41870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4749bb52c3f240fca299f90ebc8f9614",
              "IPY_MODEL_902eb5330696463ea91a614a54e383bc",
              "IPY_MODEL_069e55fe23cf4763a053f2bd4c0c2504"
            ],
            "layout": "IPY_MODEL_205529937a9d4985a880ed715330e485"
          }
        },
        "4749bb52c3f240fca299f90ebc8f9614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc3b0f9fcaf4c4e9be0a24c4c136cb7",
            "placeholder": "​",
            "style": "IPY_MODEL_73fb70dce4a4405483a0b88aab754d74",
            "value": "100%"
          }
        },
        "902eb5330696463ea91a614a54e383bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb58744a7bf544c894e63e55d0c71029",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a13b6a2ade7b4689b13892ab316f56a8",
            "value": 46830571
          }
        },
        "069e55fe23cf4763a053f2bd4c0c2504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae19d5f2cab942069eb55195cc0a534e",
            "placeholder": "​",
            "style": "IPY_MODEL_7fa3307d735148f993c634f9d41b2f2d",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 114MB/s]"
          }
        },
        "205529937a9d4985a880ed715330e485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc3b0f9fcaf4c4e9be0a24c4c136cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73fb70dce4a4405483a0b88aab754d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb58744a7bf544c894e63e55d0c71029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13b6a2ade7b4689b13892ab316f56a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae19d5f2cab942069eb55195cc0a534e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa3307d735148f993c634f9d41b2f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlH5deXHdvec",
        "outputId": "3c2b2471-0029-4b8c-adb4-672dcef5b180"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5_b0TzLUn2b",
        "outputId": "0cb04164-9e8b-4c6e-cc9e-eaf398b6696c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gdrive/My\\ Drive/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99MbYEbZV0A2",
        "outputId": "cac33ca4-e6d0-4a6d-e30f-3c052d040031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data\t     data_alfonso   full_data.zip   task1   task3   task5   task7\n",
            "'data (1)'   data.zip\t    old_data.zip    task2   task4   task6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/data/data.zip > /dev/null"
      ],
      "metadata": {
        "id": "52JcHik5UoTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THESE BOTTOM COMMAND IS FOR ALFONSO SINCE I HAD TO CREATE A SHORTCUT TO THE OG DATASET"
      ],
      "metadata": {
        "id": "kgqEn3G_n5xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gdrive/My\\ Drive\\/data_alfonso/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5_jhiLIlNpK",
        "outputId": "f8dfa2d5-42a1-48c1-fbf2-ebce0173cbe7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data\t        data_all_final.zip   full_data.zip   task2   task5\n",
            "'data (1)'      data_smaller.zip     old_data.zip    task3   task6\n",
            " data_alfonso   data.zip\t     task1\t     task4   task7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  gdrive/My\\ Drive\\/data_alfonso/data/data_all_final.zip > /dev/nully"
      ],
      "metadata": {
        "id": "Zd517rTLoMOw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "wandb.init(project=\"jupyter-proj\",\n",
        "           config={\n",
        "               \"batch_size\": 100,\n",
        "               \"learning_rate\": 0.01,\n",
        "           })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "Ai78TUwTW_0H",
        "outputId": "71aa9dda-9323-4ac5-c350-8007e7805d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 27.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 72.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 56.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 80.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 54.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 81.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 81.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 68.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 83.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 81.7 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malv2145\u001b[0m (\u001b[33mdl4cv-project\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221206_165819-1t48i9tc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dl4cv-project/jupyter-proj/runs/1t48i9tc\" target=\"_blank\">pretty-capybara-1</a></strong> to <a href=\"https://wandb.ai/dl4cv-project/jupyter-proj\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dl4cv-project/jupyter-proj/runs/1t48i9tc?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fef942c16a0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip Dataset\n",
        "\"\"\"import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"./data.zip\",\"r\") as z:\n",
        "    z.extractall(\".\")\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "2wWjwdgp6We7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split \n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchvision.datasets import ImageFolder \n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob \n",
        "import random\n",
        "import shutil"
      ],
      "metadata": {
        "id": "uit0Kk4adxu2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move in all of our collected data\n",
        "task1_dataset = glob.glob(os.path.join('./data/task1/', '*.png'))\n",
        "task2_dataset = glob.glob(os.path.join('./data/task2/', '*.png'))\n",
        "task3_dataset = glob.glob(os.path.join('./data/task3/', '*.png'))\n",
        "task4_dataset = glob.glob(os.path.join('./data/task4/', '*.png'))\n",
        "task5_dataset = glob.glob(os.path.join('./data/task5/', '*.png'))\n",
        "task6_dataset = glob.glob(os.path.join('./data/task6/', '*.png'))\n",
        "task7_dataset = glob.glob(os.path.join('./data/task7/', '*.png'))\n",
        "\n",
        "\n",
        "if not os.path.exists(\"./training\"):\n",
        "  os.mkdir(\"./training\")\n",
        "  os.mkdir(\"./training/before\")\n",
        "  os.mkdir(\"./training/after\")\n",
        "if not os.path.exists(\"./validation\"):\n",
        "  os.mkdir(\"./validation\")\n",
        "  os.mkdir(\"./validation/before\")\n",
        "  os.mkdir(\"./validation/after\")\n",
        "if not os.path.exists(\"./test\"): \n",
        "  os.mkdir(\"./test\")\n",
        "  os.mkdir(\"./test/before\")\n",
        "  os.mkdir(\"./test/after\")\n",
        "\n",
        "# this needs to be changed to 7 when we download data correctly\n",
        "tasks = [task1_dataset, task2_dataset, task3_dataset, task4_dataset, task5_dataset, task6_dataset, task7_dataset]\n",
        "# now for each task randomly generate numbers for before and after to split\n",
        "for i in range(7):\n",
        "  current_task = tasks[i]\n",
        "  training_size = int(len(current_task) * .8)\n",
        "  test_size = int(len(current_task) * .1)\n",
        "  val_size = int(len(current_task) * .1)\n",
        "\n",
        "  # randomly choose an element\n",
        "  generated_list = [j+1 for j in range(int(len(current_task) / 2))] \n",
        "  \n",
        "  # add elements to our training array\n",
        "  for k in range(int(training_size / 2)):\n",
        "    random_index = random.randint(0,len(generated_list)-1)\n",
        "    random_element = generated_list[random_index]\n",
        "\n",
        "    # add the after and before images corresponding to this number \n",
        "    shutil.copy(f\"./data/task{i+1}/before{random_element}.png\", f\"./training/before/task{i+1}_before_{random_element}.png\")\n",
        "    shutil.copy(f\"./data/task{i+1}/after{random_element}.png\", f\"./training/after/task{i+1}_after_{random_element}.png\")\n",
        "\n",
        "    # remove that this element can be selected again\n",
        "    del generated_list[random_index]\n",
        "\n",
        "\n",
        "  # add elements to our test\n",
        "  for k in range(int(test_size / 2)):\n",
        "\n",
        "    random_index = random.randint(0,len(generated_list)-1)\n",
        "    random_element = generated_list[random_index]\n",
        "\n",
        "    # add the after and before images corresponding to this number \n",
        "    shutil.copy(f\"./data/task{i+1}/before{random_element}.png\", f\"./test/before/task{i+1}_before_{random_element}.png\")\n",
        "    shutil.copy(f\"./data/task{i+1}/after{random_element}.png\", f\"./test/after/task{i+1}_after_{random_element}.png\")\n",
        "\n",
        "    # remove that this element can be selected again\n",
        "    del generated_list[random_index]\n",
        "\n",
        "  \n",
        "  # add elements to our validation\n",
        "  for k in range(int(val_size / 2)):\n",
        "\n",
        "    random_index = random.randint(0,len(generated_list)-1)\n",
        "    random_element = generated_list[random_index]\n",
        "\n",
        "    # add the after and before images corresponding to this number \n",
        "    shutil.copy(f\"./data/task{i+1}/before{random_element}.png\", f\"./validation/before/task{i+1}_before_{random_element}.png\")\n",
        "    shutil.copy(f\"./data/task{i+1}/after{random_element}.png\", f\"./validation/after/task{i+1}_after_{random_element}.png\")\n",
        "\n",
        "    # remove that this element can be selected again\n",
        "    del generated_list[random_index]\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "tn6fGoaH7X7e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transforms\n",
        "dim = 512\n",
        "def get_train_transform():\n",
        "    return transforms.Compose([\n",
        "    transforms.Resize((dim, dim)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0, 0, 0),(1, 1, 1))\n",
        "    ])\n",
        "\n",
        "def get_val_transform(): \n",
        "    return transforms.Compose([\n",
        "    transforms.Resize((dim,dim)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0, 0, 0),(1, 1, 1))\n",
        "    ])"
      ],
      "metadata": {
        "id": "mkvNY1-9BKOe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Dataset\n",
        "# Source: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
        "class CreateDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, imgs, class_to_int, folder_type, transforms = None):\n",
        "        super().__init__()\n",
        "        self.imgs = imgs\n",
        "        self.class_to_int = class_to_int\n",
        "        self.transforms = transforms\n",
        "        self.folder_type = folder_type\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.imgs[idx]\n",
        "        #print(image_name + \"\\n\")\n",
        "        indicators = image_name.split(\"_\")\n",
        "        task_num = indicators[0]\n",
        "        image_num = indicators[2]\n",
        "        \n",
        "        before_dir = f\"./{self.folder_type}/before/\"\n",
        "        before_img = self.transforms(Image.open(before_dir + image_name).convert('RGB'))\n",
        "        after_dir = f\"./{self.folder_type}/after/\"\n",
        "        after_image_name = task_num + \"_after_\" + image_num\n",
        "        after_img = self.transforms(Image.open(after_dir + after_image_name).convert('RGB'))\n",
        "\n",
        "        label = self.class_to_int[task_num]\n",
        "        label = torch.tensor(label, dtype = torch.float32)\n",
        "\n",
        "        image_list = [before_img, after_img]\n",
        "\n",
        "        return image_list, label\n",
        "            \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "iOlPavmvBAo0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"./training/before/\"\n",
        "train_images = os.listdir(train_dir) \n",
        "\n",
        "val_dir = \"./validation/before/\"\n",
        "val_images = os.listdir(val_dir) \n",
        "\n",
        "test_dir = \"./test/before/\"\n",
        "test_images = os.listdir(test_dir) "
      ],
      "metadata": {
        "id": "pwoS-u1WEo_p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Datasets to be used by Data Loaders\n",
        "class_mapping = {\"task1\" : 0, \"task2\" : 1, \"task3\" : 2, \"task4\": 3, \"task5\": 4, \"task6\": 5, \"task7\": 6}\n",
        "train_data = CreateDataset(train_images, class_mapping, folder_type = \"training\", transforms = get_train_transform())\n",
        "val_data = CreateDataset(val_images, class_mapping, folder_type = \"validation\", transforms = get_val_transform())\n",
        "test_data = CreateDataset(test_images, class_mapping, folder_type = \"test\", transforms = get_val_transform())"
      ],
      "metadata": {
        "id": "vgaB9ZOHBNXi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "batch_size = 16\n",
        "num_workers = 1\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "validation_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "lEJNtHB0BN2l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num training images: ' + str(len(train_loader.dataset)))\n",
        "print('Num validation images: ' + str(len(validation_loader.dataset)))\n",
        "print('Num test images: ' + str(len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRrSX0_Cp38Q",
        "outputId": "b0ffb951-9e74-4750-92b1-ae65395d875b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num training images: 347\n",
            "Num validation images: 40\n",
            "Num test images: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "\n",
        "ResNet18 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "ResNet18_mask = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)"
      ],
      "metadata": {
        "id": "kn2oqt1jeLI0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "8d67572e2cd3425cad8e5ff88fb41870",
            "4749bb52c3f240fca299f90ebc8f9614",
            "902eb5330696463ea91a614a54e383bc",
            "069e55fe23cf4763a053f2bd4c0c2504",
            "205529937a9d4985a880ed715330e485",
            "8cc3b0f9fcaf4c4e9be0a24c4c136cb7",
            "73fb70dce4a4405483a0b88aab754d74",
            "eb58744a7bf544c894e63e55d0c71029",
            "a13b6a2ade7b4689b13892ab316f56a8",
            "ae19d5f2cab942069eb55195cc0a534e",
            "7fa3307d735148f993c634f9d41b2f2d"
          ]
        },
        "outputId": "0484cb31-3b94-44d2-a104-2a7e5bf3365c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d67572e2cd3425cad8e5ff88fb41870"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJUOYAXqqRrt",
        "outputId": "0b8c17e0-02c2-4369-8489-1ba2ddfba1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CUT OFF THE LAYERS AT THE END\n",
        "\n",
        "ResNet18.fc = nn.Sequential(\n",
        "   nn.Linear(512, 512)\n",
        ")\n",
        "\n",
        "ResNet18_mask.fc = nn.Sequential(\n",
        "   nn.Linear(512, 512)\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bYdvx0k9eR_e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikeXRF2lqLer",
        "outputId": "65bb207e-2a60-45ca-b94b-e0db8bb1775a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMBINE BOTH MODELS INTO ONE CLASS\n",
        "class ActionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ActionModel, self).__init__()\n",
        "\n",
        "    # NETWORK A IS OUR FIRST RESNET that encodes the images \n",
        "    self.img_encoder = ResNet18\n",
        "    self.mask_encoder = ResNet18_mask\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(1536,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 7),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "\n",
        "  # forward propogation into our model\n",
        "  def forward(self, before_image, after_image, mask_image):\n",
        "\n",
        "      # run forward prop on the before image\n",
        "      before_encoded = self.img_encoder(before_image)\n",
        "\n",
        "      # run forward prop on the after image\n",
        "      after_encoded = self.img_encoder(after_image)\n",
        "\n",
        "      mask_encoded = self.mask_encoder(mask_image)\n",
        "\n",
        "      # combine our encodings\n",
        "      images_combined = torch.cat((before_encoded, after_encoded, mask_encoded), 1)\n",
        "\n",
        "      \n",
        "\n",
        "      #run final layer of model and return the highest value\n",
        "      return self.fc(images_combined)\n"
      ],
      "metadata": {
        "id": "Bp0XL8Qwfhhu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Utility Functions \n",
        "import numpy as np\n",
        "#Accuracy function \n",
        "def accuracy(preds, labels):\n",
        "  _, pred = torch.max(preds, dim=1)\n",
        "  return torch.sum(pred==labels).item()/len(labels)\n",
        "\n",
        "def check_model_accuracy(model, dloader):\n",
        "    model.eval()\n",
        "    acc = 0\n",
        "    mistakes = []\n",
        "    incorrect_before = []\n",
        "    incorrect_after = []\n",
        "    incorrect_mask = []\n",
        "    incorrect_labels = []\n",
        "    correct_labels = []\n",
        "\n",
        "    correct_before = []\n",
        "    correct_after = []\n",
        "    correct_mask = []\n",
        "    correct_labels_for_correct = []\n",
        "\n",
        "    for batch, (X, y) in enumerate(dloader):\n",
        "        #convert batch into variable that can have gradients applied to them\n",
        "        X[0] = X[0].to(device)\n",
        "        X[1] = X[1].to(device)\n",
        "\n",
        "        masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "        masks_numbers = np.empty(masks.shape)\n",
        "        masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "        masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "        masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "        rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "        rgb_masks = rgb_masks.to(device)\n",
        "        y = y.to(device)\n",
        "        #forward pass thru net\n",
        "        preds = model(X[0], X[1], rgb_masks)\n",
        "\n",
        "        prediction_final = torch.argmax(preds, dim=1).float()\n",
        "        prediction_numpy = prediction_final.cpu().detach().numpy() \n",
        "        target_numpy = y.cpu().numpy()\n",
        "\n",
        "\n",
        "        for i in range(len(prediction_numpy)):\n",
        "          prediction = int(prediction_numpy[i])\n",
        "          target = int(target_numpy[i])\n",
        "\n",
        "          if prediction != target:\n",
        "       \n",
        "            incorrect_before.append(X[0][i].clamp(0,1).cpu().numpy())\n",
        "            incorrect_after.append(X[1][i].clamp(0,1).cpu().numpy())\n",
        "            incorrect_mask.append(rgb_masks[i].clamp(0,1).cpu().numpy() )\n",
        "            incorrect_labels.append(prediction)\n",
        "            correct_labels.append(target)\n",
        "\n",
        "          else:\n",
        "            correct_before.append(X[0][i].clamp(0,1).cpu().numpy())\n",
        "            correct_after.append(X[1][i].clamp(0,1).cpu().numpy())\n",
        "            correct_mask.append(rgb_masks[i].clamp(0,1).cpu().numpy())\n",
        "            correct_labels_for_correct.append(target)\n",
        "\n",
        "\n",
        "        #check accuracy\n",
        "        acc+=accuracy(preds, y)\n",
        "\n",
        "    return acc/len(dloader), correct_before, correct_after, correct_mask, correct_labels_for_correct, incorrect_before, incorrect_after, incorrect_mask, incorrect_labels, correct_labels"
      ],
      "metadata": {
        "id": "GhoqZN8dlxRG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ActionModel()"
      ],
      "metadata": {
        "id": "Lxavk9TtoJij"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqypb4lKoLga",
        "outputId": "1307d3d5-4033-4bc4-a823-16cebc0a0613"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ActionModel(\n",
              "  (img_encoder): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (mask_encoder): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=256, out_features=7, bias=True)\n",
              "    (7): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN THE MODEL\n",
        "# %%wandb\n",
        "\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "#Freeze initial layers\n",
        "\n",
        "for i, child in enumerate(model.img_encoder.children()):\n",
        "    if i<9:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False \n",
        "    else:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "#init SGD optimizer & CrossEntropyLoss function\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=.9 )\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#put on device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "n_epochs = 20\n",
        "step=0\n",
        "lowest_val_accuracy = 0\n",
        "#Loop thru epochs \n",
        "for i in range(n_epochs):\n",
        "    val_losses = []\n",
        "    \n",
        "    #loop thru samples\n",
        "    for idx, (X, y) in enumerate(train_loader):\n",
        "        \n",
        "        X[0] = X[0].to(device)\n",
        "        X[1] = X[1].to(device)\n",
        "        masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "        masks_numbers = np.empty(masks.shape)\n",
        "        masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "        masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "        masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "        rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "        # print(X[0].shape)\n",
        "        # print(X[1].shape)\n",
        "        # print(mask.shape)\n",
        "\n",
        "        mask = masks.repeat(1,3,1,1)\n",
        "        # print(mask.shape)\n",
        "\n",
        "        # print(X[0][0].shape)\n",
        "        # print(X[1][0].shape)\n",
        "        # print(mask[0].shape)\n",
        "\n",
        "        result = np.concatenate((X[0][0].cpu().numpy(), X[1][0].cpu().numpy(), mask[0].cpu().numpy()), axis=2)\n",
        "\n",
        "        y = y.to(device)\n",
        "        \n",
        "        #make predictions\n",
        "        rgb_masks = rgb_masks.to(device)\n",
        "        preds = model(X[0], X[1], rgb_masks)\n",
        "\n",
        "        p_idx = np.argmax(preds.cpu().detach().numpy()[0], axis=0)\n",
        "        gt = str(int(y.cpu().detach()[0].item()))\n",
        "\n",
        "        #calculate loss \n",
        "        loss = loss_fn(preds.cpu(), y.cpu().to(torch.long))\n",
        "        print(loss)\n",
        "\n",
        "        #log the training loss \n",
        "        # wandb.log({\"train_loss\": loss})\n",
        "\n",
        "        #backprop\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "        #logging \n",
        "        if step%50==0:\n",
        "\n",
        "            #visualize a result from the training\n",
        "            plt.imsave(\"./training_images/epoch_\"+str(i)+\"_step_\"+str(idx)+\"_GT_\"+gt+\"_P_\"+str(p_idx)+\".jpg\", np.moveaxis(result,0,-1))\n",
        "\n",
        "            #calculate accuracy \n",
        "            model.eval()\n",
        "            val_acc=0\n",
        "            val_loss=0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch, (X, y) in enumerate(validation_loader):\n",
        "\n",
        "                    X[0] = X[0].to(device)\n",
        "                    X[1] = X[1].to(device)\n",
        "          \n",
        "                    masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "                    masks_numbers = np.empty(masks.shape)\n",
        "                    masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "                    masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "                    masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "                    rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "                    rgb_masks = rgb_masks.to(device)\n",
        "                    y = y.to(device)\n",
        "                    preds = model(X[0],X[1], rgb_masks)\n",
        "                    \n",
        "                    val_loss+=loss_fn(preds.cpu(), y.cpu().to(torch.long))\n",
        "                    val_acc+=accuracy(preds.cpu(), y.cpu())\n",
        "                \n",
        "                #normalize val accuracy and loss\n",
        "                val_acc = val_acc / len(validation_loader)\n",
        "                val_loss = val_loss / len(validation_loader)\n",
        "\n",
        "                #wandb.log({\"val_loss\": val_loss})\n",
        "                #wandb.log({\"val_acc\": val_acc})\n",
        "                    \n",
        "                #early stopping\n",
        "                if len(val_losses)>5:\n",
        "                    if val_loss >= (sum(val_losses[i-5:i])/5):\n",
        "                        print(\"Stopped at Epoch: \", idx)\n",
        "                        break\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "        step+=1\n",
        "\n",
        "    if len(val_losses) > 0:\n",
        "\n",
        "      print(\"Epoch: \", i, \" Val Loss: \", val_losses[-1], \" Val Accuracy: \", val_acc)\n",
        "\n",
        "      # save the best model performing so far\n",
        "      if val_acc > lowest_val_accuracy:\n",
        "        torch.save(model.state_dict(), \"./model_learning_rate_1e-2.pth\")\n",
        "        lowest_val_accuracy = val_acc\n"
      ],
      "metadata": {
        "id": "J3BPAQthef_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434800d4-e517-4474-b4bf-5ffe4c0267e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.9450, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9476, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9457, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9464, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9462, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9444, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9467, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9449, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9449, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9456, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9450, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9436, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9451, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9424, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9431, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9450, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9419, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9422, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9433, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  0  Val Loss:  tensor(1.9456)  Val Accuracy:  0.20833333333333334\n",
            "tensor(1.9385, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9428, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9433, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9382, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9402, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9335, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9372, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9337, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9417, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9439, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9301, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9011, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9288, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8985, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9003, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8506, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9082, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8257, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0933, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9500, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9946, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9277, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9000, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9141, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0240, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9691, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9930, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9470, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9196, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9208, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8423, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0311, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8237, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8444, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1000, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0225, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9814, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0077, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9270, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6434, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9084, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0134, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9612, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9124, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  2  Val Loss:  tensor(1.9347)  Val Accuracy:  0.14583333333333334\n",
            "tensor(1.9485, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9672, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9217, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9697, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9173, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8706, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0119, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9185, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8892, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8041, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9112, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8613, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8523, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8641, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7733, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9280, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8628, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9227, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8318, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8673, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8825, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9328, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9353, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8780, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8864, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9373, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9671, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9161, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8170, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9223, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9793, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7873, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8829, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9006, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8775, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8994, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7043, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8209, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9697, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9293, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9292, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8386, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9657, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0488, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  4  Val Loss:  tensor(1.9060)  Val Accuracy:  0.2916666666666667\n",
            "tensor(2.0474, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8848, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8708, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8484, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8920, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8569, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9411, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9415, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9570, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9333, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9308, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9323, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9437, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9371, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9307, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9263, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9296, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9351, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9279, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8965, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9481, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9061, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9435, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7836, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8666, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7501, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8212, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9011, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9477, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9013, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8692, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8149, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9979, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7934, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9108, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8943, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8803, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8043, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8123, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8188, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9503, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8160, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8166, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  6  Val Loss:  tensor(1.8339)  Val Accuracy:  0.2916666666666667\n",
            "tensor(1.7184, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9693, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7675, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8760, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0042, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0423, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8544, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9390, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7554, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7897, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7696, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7164, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9549, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8951, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9070, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8183, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1393, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7883, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8531, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9621, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9476, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0121, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9965, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0448, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9834, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9602, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9342, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9904, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7187, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9328, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8583, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9175, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9538, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9552, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9121, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8472, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8448, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1170, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9303, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7724, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5948, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8328, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7423, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7884, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7882, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9395, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8818, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9348, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8432, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6472, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8874, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7704, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8344, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9111, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8815, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9502, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7459, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8703, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8683, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8502, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7926, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7193, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8031, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6148, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7962, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9763, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  9  Val Loss:  tensor(1.8614)  Val Accuracy:  0.2916666666666667\n",
            "tensor(1.9726, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7889, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8063, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7904, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9787, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9803, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0745, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9836, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  11  Val Loss:  tensor(2.0196)  Val Accuracy:  0.14583333333333334\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9836, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  13  Val Loss:  tensor(2.0196)  Val Accuracy:  0.14583333333333334\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7904, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9836, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  15  Val Loss:  tensor(2.0196)  Val Accuracy:  0.14583333333333334\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8927, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9836, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0745, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  18  Val Loss:  tensor(2.0196)  Val Accuracy:  0.14583333333333334\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1654, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8529, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9154, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9779, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1029, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0404, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0745, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST THE MODEL\n",
        "model.load_state_dict(torch.load(\"./model_learning_rate_1e-2.pth\"))\n",
        "#Evaluate the accuracy on the test set.\n",
        "accuracy , correct_before, correct_after, correct_mask, correct_labels_for_correct, incorrect_before, incorrect_after, incorrect_mask, incorrect_labels, correct_labels = check_model_accuracy(model, test_loader)\n",
        "print(\"ACCURACY: \", accuracy)"
      ],
      "metadata": {
        "id": "XCtxeGkdejVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4404c20-40fe-4387-ea49-2be78adf42a4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY:  0.2916666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unfreeze all layers.\n",
        "\n",
        "for i, param in enumerate(model.parameters()):\n",
        "    param.requires_grad = True \n",
        "\n",
        "#Continue Fine Tuning\n",
        "\n",
        "#init SGD optimizer & CrossEntropyLoss function\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.9 )\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#put on device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "n_epochs = 20\n",
        "step=0\n",
        "lowest_val_accuracy = 0\n",
        "#Loop thru epochs \n",
        "for i in range(n_epochs):\n",
        "    val_losses = []\n",
        "    \n",
        "    #loop thru samples\n",
        "    for idx, (X, y) in enumerate(train_loader):\n",
        "        \n",
        "        X[0] = X[0].to(device)\n",
        "        X[1] = X[1].to(device)\n",
        "        masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "        masks_numbers = np.empty(masks.shape)\n",
        "        masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "        masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "        masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "        rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "        # print(X[0].shape)\n",
        "        # print(X[1].shape)\n",
        "        # print(mask.shape)\n",
        "\n",
        "        mask = masks.repeat(1,3,1,1)\n",
        "        # print(mask.shape)\n",
        "\n",
        "        # print(X[0][0].shape)\n",
        "        # print(X[1][0].shape)\n",
        "        # print(mask[0].shape)\n",
        "\n",
        "        result = np.concatenate((X[0][0].cpu().numpy(), X[1][0].cpu().numpy(), mask[0].cpu().numpy()), axis=2)\n",
        "\n",
        "        y = y.to(device)\n",
        "        \n",
        "        #make predictions\n",
        "        rgb_masks = rgb_masks.to(device)\n",
        "        preds = model(X[0], X[1], rgb_masks)\n",
        "\n",
        "        p_idx = np.argmax(preds.cpu().detach().numpy()[0], axis=0)\n",
        "        gt = str(int(y.cpu().detach()[0].item()))\n",
        "\n",
        "        #calculate loss \n",
        "        loss = loss_fn(preds.cpu(), y.cpu().to(torch.long))\n",
        "        print(loss)\n",
        "\n",
        "        #log the training loss \n",
        "        # wandb.log({\"train_loss\": loss})\n",
        "\n",
        "        #backprop\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "        #logging \n",
        "        if step%50==0:\n",
        "\n",
        "            #visualize a result from the training\n",
        "            plt.imsave(\"./training_images/epoch_\"+str(i)+\"_step_\"+str(idx)+\"_GT_\"+gt+\"_P_\"+str(p_idx)+\".jpg\", np.moveaxis(result,0,-1))\n",
        "\n",
        "            #calculate accuracy \n",
        "            model.eval()\n",
        "            val_acc=0\n",
        "            val_loss=0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch, (X, y) in enumerate(validation_loader):\n",
        "\n",
        "                    X[0] = X[0].to(device)\n",
        "                    X[1] = X[1].to(device)\n",
        "          \n",
        "                    masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "                    masks_numbers = np.empty(masks.shape)\n",
        "                    masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "                    masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "                    masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "                    rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "                    rgb_masks = rgb_masks.to(device)\n",
        "                    y = y.to(device)\n",
        "                    preds = model(X[0],X[1], rgb_masks)\n",
        "                    \n",
        "                    val_loss+=loss_fn(preds.cpu(), y.cpu().to(torch.long))\n",
        "                    val_acc+=accuracy(preds.cpu(), y.cpu())\n",
        "                \n",
        "                #normalize val accuracy and loss\n",
        "                val_acc = val_acc / len(validation_loader)\n",
        "                val_loss = val_loss / len(validation_loader)\n",
        "\n",
        "                #wandb.log({\"val_loss\": val_loss})\n",
        "                #wandb.log({\"val_acc\": val_acc})\n",
        "                    \n",
        "                #early stopping\n",
        "                if len(val_losses)>5:\n",
        "                    if val_loss >= (sum(val_losses[i-5:i])/5):\n",
        "                        print(\"Stopped at Epoch: \", idx)\n",
        "                        break\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "        step+=1\n",
        "\n",
        "    if len(val_losses) > 0:\n",
        "      print(\"Epoch: \", i, \" Val Loss: \", val_losses[-1], \" Val Accuracy: \", val_acc)\n",
        "      if val_acc > lowest_val_accuracy:\n",
        "        torch.save(model.state_dict(), \"./model_learning_rate_1e-2.pth\")\n",
        "        lowest_val_accuracy = val_acc"
      ],
      "metadata": {
        "id": "BTMggfw4l6Xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c608a18-86b6-4c0e-fbc3-2d41e8fa1ce1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.9521, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9355, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9206, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9177, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7932, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0567, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8866, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8785, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8843, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6904, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0158, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8620, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7912, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8162, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9194, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8568, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8642, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8799, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8658, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0081, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9570, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8612, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  0  Val Loss:  tensor(1.9206)  Val Accuracy:  0.2916666666666667\n",
            "tensor(1.8054, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8307, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8425, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9193, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8865, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8475, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7771, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9224, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9035, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8356, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9399, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9371, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9762, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8212, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8826, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8480, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8498, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8847, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8557, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9343, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8803, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9278, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9018, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9208, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8668, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8976, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7750, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8944, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9206, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7972, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8748, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7717, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8908, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9259, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9451, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8859, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9498, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6669, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8471, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8479, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8550, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9291, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8878, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9353, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  2  Val Loss:  tensor(1.8752)  Val Accuracy:  0.2916666666666667\n",
            "tensor(1.8874, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9399, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8662, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7143, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9534, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9165, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8784, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8805, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8070, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8603, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8063, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7954, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8678, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9281, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7772, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8740, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9155, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9068, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8899, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8976, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7651, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9035, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9642, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8623, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8304, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9307, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8367, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8034, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9325, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7769, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7709, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9732, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8908, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8823, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8817, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7822, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8365, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7759, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9183, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9237, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7537, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9060, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8022, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8783, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  4  Val Loss:  tensor(1.8699)  Val Accuracy:  0.2916666666666667\n",
            "tensor(1.8138, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8192, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9676, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8408, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9111, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9229, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9347, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6894, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9040, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8233, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8674, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7383, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7737, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8561, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8043, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8453, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9447, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6816, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8533, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8616, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9371, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8892, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0251, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9026, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7949, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7991, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8340, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6627, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8747, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8853, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8007, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9219, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8304, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8040, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8773, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8071, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9031, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8806, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7405, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7895, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7890, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8853, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7362, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7657, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  6  Val Loss:  tensor(1.8375)  Val Accuracy:  0.3333333333333333\n",
            "tensor(1.7691, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5886, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7440, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7659, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6643, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8352, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8428, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8457, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8174, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7726, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0162, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7820, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9158, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8084, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8525, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9272, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8101, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8431, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8005, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8151, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9622, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7680, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8539, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7098, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7432, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7482, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7590, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7833, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8185, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7436, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7573, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6570, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8307, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6788, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9543, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8202, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7538, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8073, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8930, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8524, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7511, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8077, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7797, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7151, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8336, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7653, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7394, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6905, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7120, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8638, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7541, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8691, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7865, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6930, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8693, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5543, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6369, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8748, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7197, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8369, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6969, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6170, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4906, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7911, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8926, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4794, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  9  Val Loss:  tensor(1.7517)  Val Accuracy:  0.4791666666666667\n",
            "tensor(1.5316, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6884, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5453, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7592, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6424, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5040, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8205, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6737, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7876, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5968, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9078, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5329, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9563, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6837, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6536, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9035, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8626, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8078, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8204, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7428, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6806, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9065, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7670, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9223, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9337, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8457, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6851, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6310, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8046, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8165, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5702, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7594, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5639, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7669, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8975, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6811, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6497, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6748, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6939, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6611, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6953, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7133, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5698, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7814, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  11  Val Loss:  tensor(1.7543)  Val Accuracy:  0.4583333333333333\n",
            "tensor(1.6234, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8361, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8591, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7221, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5090, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7055, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7929, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6481, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6489, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7503, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6690, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6449, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3849, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7255, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7262, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5923, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7828, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6460, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7552, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9671, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6319, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7113, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8197, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5750, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7413, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6583, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9328, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6844, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8571, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6018, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5745, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8152, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7315, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6854, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6831, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6237, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6367, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5215, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6143, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5291, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9149, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5701, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5380, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  13  Val Loss:  tensor(1.6246)  Val Accuracy:  0.5833333333333334\n",
            "tensor(1.6774, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8163, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6774, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5095, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7434, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4740, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6620, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7580, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6636, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6183, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5794, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7407, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7280, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6708, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8572, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6465, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7046, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7699, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5877, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4242, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7795, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6693, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7915, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5714, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8521, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6700, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5800, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6795, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9806, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7354, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7315, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6752, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7431, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8567, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6528, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7820, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7462, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6289, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6445, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4872, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7887, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8867, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7023, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  15  Val Loss:  tensor(1.7024)  Val Accuracy:  0.4375\n",
            "tensor(1.6945, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7709, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7584, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6177, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5991, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7276, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5370, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6669, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6909, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6306, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8309, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7924, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8691, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5452, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7941, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7317, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6943, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7093, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7593, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7107, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7717, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5839, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7550, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6121, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7536, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7685, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4153, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6442, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7691, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6977, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8680, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5956, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7151, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5331, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9827, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7490, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9107, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8347, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5472, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7454, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6557, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6711, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7345, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7160, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7334, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6732, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9536, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6057, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6704, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8112, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7900, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6867, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7258, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6346, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6355, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6503, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4921, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6747, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8866, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6709, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9765, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6737, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9663, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1027, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9866, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  18  Val Loss:  tensor(1.6526)  Val Accuracy:  0.5208333333333334\n",
            "tensor(1.8447, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9059, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9463, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0564, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0177, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9979, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8923, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8395, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7733, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9675, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6651, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9664, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6783, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5648, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9648, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6967, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8990, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8519, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8987, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8109, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8508, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7861, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the model and evaluating it is easier than running the above\n",
        "#torch.save(model.state_dict(), \"./model_learning_rate_1e-2.pth\")"
      ],
      "metadata": {
        "id": "G4jgLXytuKOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# newModel = ActionModel()\n",
        "model.load_state_dict(torch.load(\"./model_learning_rate_1e-2.pth\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAcgIBPEw_80",
        "outputId": "3f0e8673-7f74-4cc5-a5ea-5141f37cd48d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyDiLSP559sB",
        "outputId": "9b6caa56-c959-4a93-ac4d-74729e81512a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#put on device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "accuracy , correct_before, correct_after, correct_mask, correct_labels_for_correct, incorrect_before, incorrect_after, incorrect_mask, incorrect_labels, correct_labels = check_model_accuracy(model, test_loader)"
      ],
      "metadata": {
        "id": "Tms8RbvK49Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba943cb-08c7-4c38-c4d5-cf0c57e4c651"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8oNg86l65NM",
        "outputId": "189f0652-ad05-4335-b669-c68fd9e8473f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# let us plot the first 5 sample mistakes\n",
        "for i in range(5):\n",
        "\n",
        "  mistake_img_before = incorrect_before[i]\n",
        "  mistake_img_after = incorrect_after[i]\n",
        "  mistake_img_mask =  incorrect_mask[i]\n",
        "\n",
        "\n",
        "  result = np.concatenate((mistake_img_before, mistake_img_after, mistake_img_mask), axis=2)\n",
        "  result = np.moveaxis(result, 0, -1)\n",
        "\n",
        "  plt.imsave(\"./sample_mistakes/predicted_\" +  str(incorrect_labels[i]) + \"_correct_\"+ str(correct_labels[i]) + \".jpg\", result)\n",
        "  # plt.show()\n",
        "  print(\"PREDICTED LABEL: \" + str(incorrect_labels[i]))\n",
        "  print(\"CORRECT LABEL: \" + str(correct_labels[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inbmWDEE661o",
        "outputId": "55ce25b4-0043-45ca-de9a-ca7613c1845b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREDICTED LABEL: 1\n",
            "CORRECT LABEL: 3\n",
            "PREDICTED LABEL: 1\n",
            "CORRECT LABEL: 2\n",
            "PREDICTED LABEL: 1\n",
            "CORRECT LABEL: 2\n",
            "PREDICTED LABEL: 4\n",
            "CORRECT LABEL: 6\n",
            "PREDICTED LABEL: 2\n",
            "CORRECT LABEL: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# let us plot the first 5 sample mistakes\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  correct_img_before = correct_before[i]\n",
        "  correct_img_after = correct_after[i]\n",
        "  correct_img_mask =  correct_mask[i]\n",
        "\n",
        "  result = np.concatenate((correct_img_before, correct_img_after, correct_img_mask), axis=2)\n",
        "  result = np.moveaxis(result, 0, -1)\n",
        "  print(result.shape)\n",
        "  plt.imsave(\"./sample_correct/correct_\"+ str(correct_labels_for_correct[i]) + \".jpg\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-7ep3y6Bbx9",
        "outputId": "e88e0b63-1a0d-483d-886b-b4e4cc128452"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 1536, 3)\n",
            "(512, 1536, 3)\n",
            "(512, 1536, 3)\n",
            "(512, 1536, 3)\n",
            "(512, 1536, 3)\n"
          ]
        }
      ]
    }
  ]
}
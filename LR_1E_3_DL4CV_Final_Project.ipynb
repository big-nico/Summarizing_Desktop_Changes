{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "325c1bc43c2146e69b65783a1c3b96c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2543715d8b6349debac2ca50725395b6",
              "IPY_MODEL_228fba33a7264e2ba3ae02ab4ef221d4",
              "IPY_MODEL_0480162b8fee4db29a65bc34e0a6faf0"
            ],
            "layout": "IPY_MODEL_5c36eb4e6e044977add900554ed933bf"
          }
        },
        "2543715d8b6349debac2ca50725395b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b77c8ca8f1a4d478bf62966e61ad9f0",
            "placeholder": "​",
            "style": "IPY_MODEL_9b75b3bfc0b94e47a70690d6dc511f53",
            "value": "100%"
          }
        },
        "228fba33a7264e2ba3ae02ab4ef221d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2a4eaa2ffd41429aea3b110d53c1a1",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c116ea926149ef8be1f345a71c4ad6",
            "value": 46830571
          }
        },
        "0480162b8fee4db29a65bc34e0a6faf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f206cf4c0340d391cc8040f3c0cc60",
            "placeholder": "​",
            "style": "IPY_MODEL_5fca8b65ed624a9ab1383f7d66a87c5e",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 82.5MB/s]"
          }
        },
        "5c36eb4e6e044977add900554ed933bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b77c8ca8f1a4d478bf62966e61ad9f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b75b3bfc0b94e47a70690d6dc511f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb2a4eaa2ffd41429aea3b110d53c1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c116ea926149ef8be1f345a71c4ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27f206cf4c0340d391cc8040f3c0cc60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fca8b65ed624a9ab1383f7d66a87c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlH5deXHdvec",
        "outputId": "99da6d77-52c4-4f44-b80b-4ffa8eb9c341"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5_b0TzLUn2b",
        "outputId": "9b80d57b-b08d-4249-d594-db5b05d7e120"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gdrive/My\\ Drive/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99MbYEbZV0A2",
        "outputId": "cac33ca4-e6d0-4a6d-e30f-3c052d040031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data\t     data_alfonso   full_data.zip   task1   task3   task5   task7\n",
            "'data (1)'   data.zip\t    old_data.zip    task2   task4   task6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/data/data.zip > /dev/null"
      ],
      "metadata": {
        "id": "52JcHik5UoTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THESE BOTTOM COMMAND IS FOR ALFONSO SINCE I HAD TO CREATE A SHORTCUT TO THE OG DATASET"
      ],
      "metadata": {
        "id": "kgqEn3G_n5xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gdrive/My\\ Drive\\/data_alfonso/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5_jhiLIlNpK",
        "outputId": "13260786-c02c-46b1-e874-13134a424b12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data\t        data_all_final.zip   full_data.zip   task2   task5\n",
            "'data (1)'      data_smaller.zip     old_data.zip    task3   task6\n",
            " data_alfonso   data.zip\t     task1\t     task4   task7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  gdrive/My\\ Drive\\/data_alfonso/data/data_all_final.zip > /dev/nully"
      ],
      "metadata": {
        "id": "Zd517rTLoMOw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "wandb.init(project=\"jupyter-proj\",\n",
        "           config={\n",
        "               \"batch_size\": 100,\n",
        "               \"learning_rate\": 0.01,\n",
        "           })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "Ai78TUwTW_0H",
        "outputId": "71aa9dda-9323-4ac5-c350-8007e7805d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 27.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 72.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 56.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 80.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 54.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 81.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 81.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 68.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 83.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 81.7 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malv2145\u001b[0m (\u001b[33mdl4cv-project\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221206_165819-1t48i9tc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dl4cv-project/jupyter-proj/runs/1t48i9tc\" target=\"_blank\">pretty-capybara-1</a></strong> to <a href=\"https://wandb.ai/dl4cv-project/jupyter-proj\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dl4cv-project/jupyter-proj/runs/1t48i9tc?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fef942c16a0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip Dataset\n",
        "\"\"\"import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"./data.zip\",\"r\") as z:\n",
        "    z.extractall(\".\")\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "2wWjwdgp6We7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split \n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchvision.datasets import ImageFolder \n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob \n",
        "import random\n",
        "import shutil"
      ],
      "metadata": {
        "id": "uit0Kk4adxu2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move in all of our collected data\n",
        "task1_dataset = glob.glob(os.path.join('./data/task1/', '*.png'))\n",
        "task2_dataset = glob.glob(os.path.join('./data/task2/', '*.png'))\n",
        "task3_dataset = glob.glob(os.path.join('./data/task3/', '*.png'))\n",
        "task4_dataset = glob.glob(os.path.join('./data/task4/', '*.png'))\n",
        "task5_dataset = glob.glob(os.path.join('./data/task5/', '*.png'))\n",
        "task6_dataset = glob.glob(os.path.join('./data/task6/', '*.png'))\n",
        "task7_dataset = glob.glob(os.path.join('./data/task7/', '*.png'))\n",
        "\n",
        "\n",
        "if not os.path.exists(\"./training\"):\n",
        "  os.mkdir(\"./training\")\n",
        "  os.mkdir(\"./training/before\")\n",
        "  os.mkdir(\"./training/after\")\n",
        "if not os.path.exists(\"./validation\"):\n",
        "  os.mkdir(\"./validation\")\n",
        "  os.mkdir(\"./validation/before\")\n",
        "  os.mkdir(\"./validation/after\")\n",
        "if not os.path.exists(\"./test\"): \n",
        "  os.mkdir(\"./test\")\n",
        "  os.mkdir(\"./test/before\")\n",
        "  os.mkdir(\"./test/after\")\n",
        "\n",
        "# this needs to be changed to 7 when we download data correctly\n",
        "tasks = [task1_dataset, task2_dataset, task3_dataset, task4_dataset, task5_dataset, task6_dataset, task7_dataset]\n",
        "# now for each task randomly generate numbers for before and after to split\n",
        "for i in range(7):\n",
        "  current_task = tasks[i]\n",
        "  training_size = int(len(current_task) * .8)\n",
        "  test_size = int(len(current_task) * .1)\n",
        "  val_size = int(len(current_task) * .1)\n",
        "\n",
        "  # randomly choose an element\n",
        "  generated_list = [j+1 for j in range(int(len(current_task) / 2))] \n",
        "  \n",
        "  # add elements to our training array\n",
        "  for k in range(int(training_size / 2)):\n",
        "    random_index = random.randint(0,len(generated_list)-1)\n",
        "    random_element = generated_list[random_index]\n",
        "\n",
        "    # add the after and before images corresponding to this number \n",
        "    shutil.copy(f\"./data/task{i+1}/before{random_element}.png\", f\"./training/before/task{i+1}_before_{random_element}.png\")\n",
        "    shutil.copy(f\"./data/task{i+1}/after{random_element}.png\", f\"./training/after/task{i+1}_after_{random_element}.png\")\n",
        "\n",
        "    # remove that this element can be selected again\n",
        "    del generated_list[random_index]\n",
        "\n",
        "\n",
        "  # add elements to our test\n",
        "  for k in range(int(test_size / 2)):\n",
        "\n",
        "    random_index = random.randint(0,len(generated_list)-1)\n",
        "    random_element = generated_list[random_index]\n",
        "\n",
        "    # add the after and before images corresponding to this number \n",
        "    shutil.copy(f\"./data/task{i+1}/before{random_element}.png\", f\"./test/before/task{i+1}_before_{random_element}.png\")\n",
        "    shutil.copy(f\"./data/task{i+1}/after{random_element}.png\", f\"./test/after/task{i+1}_after_{random_element}.png\")\n",
        "\n",
        "    # remove that this element can be selected again\n",
        "    del generated_list[random_index]\n",
        "\n",
        "  \n",
        "  # add elements to our validation\n",
        "  for k in range(int(val_size / 2)):\n",
        "\n",
        "    random_index = random.randint(0,len(generated_list)-1)\n",
        "    random_element = generated_list[random_index]\n",
        "\n",
        "    # add the after and before images corresponding to this number \n",
        "    shutil.copy(f\"./data/task{i+1}/before{random_element}.png\", f\"./validation/before/task{i+1}_before_{random_element}.png\")\n",
        "    shutil.copy(f\"./data/task{i+1}/after{random_element}.png\", f\"./validation/after/task{i+1}_after_{random_element}.png\")\n",
        "\n",
        "    # remove that this element can be selected again\n",
        "    del generated_list[random_index]\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "tn6fGoaH7X7e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transforms\n",
        "dim = 512\n",
        "def get_train_transform():\n",
        "    return transforms.Compose([\n",
        "    transforms.Resize((dim, dim)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0, 0, 0),(1, 1, 1))\n",
        "    ])\n",
        "\n",
        "def get_val_transform(): \n",
        "    return transforms.Compose([\n",
        "    transforms.Resize((dim,dim)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0, 0, 0),(1, 1, 1))\n",
        "    ])"
      ],
      "metadata": {
        "id": "mkvNY1-9BKOe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Dataset\n",
        "# Source: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
        "class CreateDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, imgs, class_to_int, folder_type, transforms = None):\n",
        "        super().__init__()\n",
        "        self.imgs = imgs\n",
        "        self.class_to_int = class_to_int\n",
        "        self.transforms = transforms\n",
        "        self.folder_type = folder_type\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.imgs[idx]\n",
        "        #print(image_name + \"\\n\")\n",
        "        indicators = image_name.split(\"_\")\n",
        "        task_num = indicators[0]\n",
        "        image_num = indicators[2]\n",
        "        \n",
        "        before_dir = f\"./{self.folder_type}/before/\"\n",
        "        before_img = self.transforms(Image.open(before_dir + image_name).convert('RGB'))\n",
        "        after_dir = f\"./{self.folder_type}/after/\"\n",
        "        after_image_name = task_num + \"_after_\" + image_num\n",
        "        after_img = self.transforms(Image.open(after_dir + after_image_name).convert('RGB'))\n",
        "\n",
        "        label = self.class_to_int[task_num]\n",
        "        label = torch.tensor(label, dtype = torch.float32)\n",
        "\n",
        "        image_list = [before_img, after_img]\n",
        "\n",
        "        return image_list, label\n",
        "            \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "iOlPavmvBAo0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"./training/before/\"\n",
        "train_images = os.listdir(train_dir) \n",
        "\n",
        "val_dir = \"./validation/before/\"\n",
        "val_images = os.listdir(val_dir) \n",
        "\n",
        "test_dir = \"./test/before/\"\n",
        "test_images = os.listdir(test_dir) "
      ],
      "metadata": {
        "id": "pwoS-u1WEo_p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Datasets to be used by Data Loaders\n",
        "class_mapping = {\"task1\" : 0, \"task2\" : 1, \"task3\" : 2, \"task4\": 3, \"task5\": 4, \"task6\": 5, \"task7\": 6}\n",
        "train_data = CreateDataset(train_images, class_mapping, folder_type = \"training\", transforms = get_train_transform())\n",
        "val_data = CreateDataset(val_images, class_mapping, folder_type = \"validation\", transforms = get_val_transform())\n",
        "test_data = CreateDataset(test_images, class_mapping, folder_type = \"test\", transforms = get_val_transform())"
      ],
      "metadata": {
        "id": "vgaB9ZOHBNXi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "batch_size = 16\n",
        "num_workers = 1\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "validation_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "lEJNtHB0BN2l"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num training images: ' + str(len(train_loader.dataset)))\n",
        "print('Num validation images: ' + str(len(validation_loader.dataset)))\n",
        "print('Num test images: ' + str(len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRrSX0_Cp38Q",
        "outputId": "31e111d7-6552-4c14-ba87-89b7f1e1d827"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num training images: 347\n",
            "Num validation images: 40\n",
            "Num test images: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "\n",
        "ResNet18 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "ResNet18_mask = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)"
      ],
      "metadata": {
        "id": "kn2oqt1jeLI0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "325c1bc43c2146e69b65783a1c3b96c9",
            "2543715d8b6349debac2ca50725395b6",
            "228fba33a7264e2ba3ae02ab4ef221d4",
            "0480162b8fee4db29a65bc34e0a6faf0",
            "5c36eb4e6e044977add900554ed933bf",
            "5b77c8ca8f1a4d478bf62966e61ad9f0",
            "9b75b3bfc0b94e47a70690d6dc511f53",
            "cb2a4eaa2ffd41429aea3b110d53c1a1",
            "88c116ea926149ef8be1f345a71c4ad6",
            "27f206cf4c0340d391cc8040f3c0cc60",
            "5fca8b65ed624a9ab1383f7d66a87c5e"
          ]
        },
        "outputId": "1d517a48-6eb2-4fcc-c445-8fa31ba9138b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "325c1bc43c2146e69b65783a1c3b96c9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJUOYAXqqRrt",
        "outputId": "0b8c17e0-02c2-4369-8489-1ba2ddfba1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CUT OFF THE LAYERS AT THE END\n",
        "\n",
        "ResNet18.fc = nn.Sequential(\n",
        "   nn.Linear(512, 512)\n",
        ")\n",
        "\n",
        "ResNet18_mask.fc = nn.Sequential(\n",
        "   nn.Linear(512, 512)\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bYdvx0k9eR_e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikeXRF2lqLer",
        "outputId": "65bb207e-2a60-45ca-b94b-e0db8bb1775a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMBINE BOTH MODELS INTO ONE CLASS\n",
        "class ActionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ActionModel, self).__init__()\n",
        "\n",
        "    # NETWORK A IS OUR FIRST RESNET that encodes the images \n",
        "    self.img_encoder = ResNet18\n",
        "    self.mask_encoder = ResNet18_mask\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(1536,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 7),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "\n",
        "  # forward propogation into our model\n",
        "  def forward(self, before_image, after_image, mask_image):\n",
        "\n",
        "      # run forward prop on the before image\n",
        "      before_encoded = self.img_encoder(before_image)\n",
        "\n",
        "      # run forward prop on the after image\n",
        "      after_encoded = self.img_encoder(after_image)\n",
        "\n",
        "      mask_encoded = self.mask_encoder(mask_image)\n",
        "\n",
        "      # combine our encodings\n",
        "      images_combined = torch.cat((before_encoded, after_encoded, mask_encoded), 1)\n",
        "\n",
        "      \n",
        "\n",
        "      #run final layer of model and return the highest value\n",
        "      return self.fc(images_combined)\n"
      ],
      "metadata": {
        "id": "Bp0XL8Qwfhhu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Utility Functions \n",
        "import numpy as np\n",
        "#Accuracy function \n",
        "def accuracy(preds, labels):\n",
        "  _, pred = torch.max(preds, dim=1)\n",
        "  return torch.sum(pred==labels).item()/len(labels)\n",
        "\n",
        "def check_model_accuracy(model, dloader):\n",
        "    model.eval()\n",
        "    acc = 0\n",
        "    mistakes = []\n",
        "    incorrect_before = []\n",
        "    incorrect_after = []\n",
        "    incorrect_mask = []\n",
        "    incorrect_labels = []\n",
        "    correct_labels = []\n",
        "\n",
        "    correct_before = []\n",
        "    correct_after = []\n",
        "    correct_mask = []\n",
        "    correct_labels_for_correct = []\n",
        "\n",
        "    for batch, (X, y) in enumerate(dloader):\n",
        "        #convert batch into variable that can have gradients applied to them\n",
        "        X[0] = X[0].to(device)\n",
        "        X[1] = X[1].to(device)\n",
        "\n",
        "        masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "        masks_numbers = np.empty(masks.shape)\n",
        "        masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "        masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "        masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "        rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "        rgb_masks = rgb_masks.to(device)\n",
        "        y = y.to(device)\n",
        "        #forward pass thru net\n",
        "        preds = model(X[0], X[1], rgb_masks)\n",
        "\n",
        "        prediction_final = torch.argmax(preds, dim=1).float()\n",
        "        prediction_numpy = prediction_final.cpu().detach().numpy() \n",
        "        target_numpy = y.cpu().numpy()\n",
        "\n",
        "\n",
        "        for i in range(len(prediction_numpy)):\n",
        "          prediction = int(prediction_numpy[i])\n",
        "          target = int(target_numpy[i])\n",
        "\n",
        "          if prediction != target:\n",
        "       \n",
        "            incorrect_before.append(X[0][i].clamp(0,1).cpu().numpy())\n",
        "            incorrect_after.append(X[1][i].clamp(0,1).cpu().numpy())\n",
        "            incorrect_mask.append(rgb_masks[i].clamp(0,1).cpu().numpy() )\n",
        "            incorrect_labels.append(prediction)\n",
        "            correct_labels.append(target)\n",
        "\n",
        "          else:\n",
        "            correct_before.append(X[0][i].clamp(0,1).cpu().numpy())\n",
        "            correct_after.append(X[1][i].clamp(0,1).cpu().numpy())\n",
        "            correct_mask.append(rgb_masks[i].clamp(0,1).cpu().numpy())\n",
        "            correct_labels_for_correct.append(target)\n",
        "\n",
        "\n",
        "        #check accuracy\n",
        "        acc+=accuracy(preds, y)\n",
        "\n",
        "    return acc/len(dloader), correct_before, correct_after, correct_mask, correct_labels_for_correct, incorrect_before, incorrect_after, incorrect_mask, incorrect_labels, correct_labels"
      ],
      "metadata": {
        "id": "GhoqZN8dlxRG"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ActionModel()"
      ],
      "metadata": {
        "id": "Lxavk9TtoJij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqypb4lKoLga",
        "outputId": "10d7ad24-94c6-4448-9388-b48b334b7d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ActionModel(\n",
              "  (img_encoder): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (mask_encoder): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=256, out_features=7, bias=True)\n",
              "    (7): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN THE MODEL\n",
        "# %%wandb\n",
        "\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "#Freeze initial layers\n",
        "\n",
        "for i, child in enumerate(model.img_encoder.children()):\n",
        "    if i<9:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False \n",
        "    else:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "#init SGD optimizer & CrossEntropyLoss function\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.9 )\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#put on device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "n_epochs = 20\n",
        "step=0\n",
        "\n",
        "#Loop thru epochs \n",
        "for i in range(n_epochs):\n",
        "    val_losses = []\n",
        "    \n",
        "    #loop thru samples\n",
        "    for idx, (X, y) in enumerate(train_loader):\n",
        "        \n",
        "        X[0] = X[0].to(device)\n",
        "        X[1] = X[1].to(device)\n",
        "        masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "        masks_numbers = np.empty(masks.shape)\n",
        "        masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "        masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "        masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "        rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "        # print(X[0].shape)\n",
        "        # print(X[1].shape)\n",
        "        # print(mask.shape)\n",
        "\n",
        "        mask = masks.repeat(1,3,1,1)\n",
        "        # print(mask.shape)\n",
        "\n",
        "        # print(X[0][0].shape)\n",
        "        # print(X[1][0].shape)\n",
        "        # print(mask[0].shape)\n",
        "\n",
        "        result = np.concatenate((X[0][0].cpu().numpy(), X[1][0].cpu().numpy(), mask[0].cpu().numpy()), axis=2)\n",
        "\n",
        "        y = y.to(device)\n",
        "        \n",
        "        #make predictions\n",
        "        rgb_masks = rgb_masks.to(device)\n",
        "        preds = model(X[0], X[1], rgb_masks)\n",
        "\n",
        "        p_idx = np.argmax(preds.cpu().detach().numpy()[0], axis=0)\n",
        "        gt = str(int(y.cpu().detach()[0].item()))\n",
        "\n",
        "        #calculate loss \n",
        "        loss = loss_fn(preds.cpu(), y.cpu().to(torch.long))\n",
        "        print(loss)\n",
        "\n",
        "        #log the training loss \n",
        "        # wandb.log({\"train_loss\": loss})\n",
        "\n",
        "        #backprop\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "        #logging \n",
        "        if step%50==0:\n",
        "\n",
        "            #visualize a result from the training\n",
        "            plt.imsave(\"./training_images/epoch_\"+str(i)+\"_step_\"+str(idx)+\"_GT_\"+gt+\"_P_\"+str(p_idx)+\".jpg\", np.moveaxis(result,0,-1))\n",
        "\n",
        "            #calculate accuracy \n",
        "            model.eval()\n",
        "            val_acc=0\n",
        "            val_loss=0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch, (X, y) in enumerate(validation_loader):\n",
        "\n",
        "                    X[0] = X[0].to(device)\n",
        "                    X[1] = X[1].to(device)\n",
        "          \n",
        "                    masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "                    masks_numbers = np.empty(masks.shape)\n",
        "                    masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "                    masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "                    masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "                    rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "                    rgb_masks = rgb_masks.to(device)\n",
        "                    y = y.to(device)\n",
        "                    preds = model(X[0],X[1], rgb_masks)\n",
        "                    \n",
        "                    val_loss+=loss_fn(preds.cpu(), y.cpu().to(torch.long))\n",
        "                    val_acc+=accuracy(preds.cpu(), y.cpu())\n",
        "                \n",
        "                #normalize val accuracy and loss\n",
        "                val_acc = val_acc / len(validation_loader)\n",
        "                val_loss = val_loss / len(validation_loader)\n",
        "\n",
        "                #wandb.log({\"val_loss\": val_loss})\n",
        "                #wandb.log({\"val_acc\": val_acc})\n",
        "                    \n",
        "                #early stopping\n",
        "                if len(val_losses)>5:\n",
        "                    if val_loss >= (sum(val_losses[i-5:i])/5):\n",
        "                        print(\"Stopped at Epoch: \", idx)\n",
        "                        break\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "        step+=1\n",
        "\n",
        "    if len(val_losses) > 0:\n",
        "      print(\"Epoch: \", i, \" Val Loss: \", val_losses[-1], \" Val Accuracy: \", val_acc)"
      ],
      "metadata": {
        "id": "J3BPAQthef_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0db8267-0333-43e6-86b5-6a234c5a7c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.9461, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9442, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9472, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9485, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9481, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9501, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9428, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9474, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9451, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9471, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9492, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9445, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9494, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9470, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9427, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9433, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9467, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9453, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9439, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9439, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9424, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  0  Val Loss:  tensor(1.9464)  Val Accuracy:  0.125\n",
            "tensor(1.9437, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9470, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9444, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9461, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9452, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9465, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9459, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9424, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9467, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9459, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9458, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9490, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9427, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9478, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9432, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9448, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9456, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9444, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9406, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9459, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9463, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9434, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9454, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9460, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9435, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9448, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9403, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9441, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9444, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9412, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9445, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9477, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9448, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9422, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9414, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9449, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9447, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9470, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9463, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9406, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9459, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9439, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  2  Val Loss:  tensor(1.9450)  Val Accuracy:  0.125\n",
            "tensor(1.9459, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9458, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9464, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9445, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9405, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9383, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9447, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9399, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9424, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9403, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9416, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9372, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9443, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9431, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9417, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9422, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9460, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9328, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9406, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9437, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9430, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9351, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9428, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9349, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9440, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9398, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9367, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9398, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9327, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9345, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9329, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9418, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9350, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9333, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9384, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9390, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9406, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9466, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  4  Val Loss:  tensor(1.9407)  Val Accuracy:  0.125\n",
            "tensor(1.9355, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9408, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9341, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9313, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9404, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9311, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9408, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9376, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9446, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9228, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9259, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9051, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9297, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9263, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9195, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9209, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9314, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9171, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9044, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9219, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9326, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8964, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9432, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9264, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9474, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9288, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8864, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9041, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8972, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9254, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8175, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8881, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9092, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8418, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8492, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8488, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8998, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8490, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9373, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8514, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8641, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8690, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9588, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9651, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  6  Val Loss:  tensor(1.9237)  Val Accuracy:  0.125\n",
            "tensor(1.9174, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9093, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8726, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9034, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9052, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9215, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8989, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8780, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8498, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9240, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8926, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8869, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8637, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8944, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8444, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8726, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9651, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8651, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9099, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8805, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8803, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8927, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8825, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9108, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8861, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9223, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8018, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9597, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8585, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8700, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8584, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9366, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8696, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9635, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9453, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8785, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8855, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9046, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8707, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8720, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8459, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8607, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8783, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9476, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8481, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8504, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8990, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9357, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8757, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9486, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9008, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8439, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8572, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8926, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8016, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8818, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9093, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9254, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9139, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7805, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8836, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9160, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8228, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8152, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9442, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8452, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  9  Val Loss:  tensor(1.8969)  Val Accuracy:  0.16666666666666666\n",
            "tensor(1.8852, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8526, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8085, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8843, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8543, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9042, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8804, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8462, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8841, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8132, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8582, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8646, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8262, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9647, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8770, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8704, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9085, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8884, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8838, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9119, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9003, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8281, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9278, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8168, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8169, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8415, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8677, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9257, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8733, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8751, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8923, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8327, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8488, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9176, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9122, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9412, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8808, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8372, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8087, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8253, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8877, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8984, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8521, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9394, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  11  Val Loss:  tensor(1.8878)  Val Accuracy:  0.22916666666666666\n",
            "tensor(1.8687, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8810, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8740, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8554, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9067, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8829, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8776, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8663, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8737, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8665, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7141, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8469, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9019, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0027, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8050, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9138, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9387, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8344, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8883, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8706, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9347, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8024, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9159, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8120, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8808, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8689, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8327, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8379, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8304, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8266, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7597, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8803, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8526, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9210, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8355, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9234, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9744, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8758, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9439, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9063, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8391, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9177, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8757, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9071, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  13  Val Loss:  tensor(1.9124)  Val Accuracy:  0.2708333333333333\n",
            "tensor(1.8712, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9339, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8677, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8403, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8344, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9413, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6813, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8282, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9400, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7332, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8329, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7601, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8863, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8492, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9342, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8427, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8415, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9196, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8538, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8626, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8578, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8743, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8943, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8726, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8464, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8133, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7826, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8787, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8362, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8860, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7606, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8150, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8165, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8115, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8031, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8869, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8681, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8991, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8374, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8314, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8408, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8268, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9440, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  15  Val Loss:  tensor(1.9126)  Val Accuracy:  0.14583333333333334\n",
            "tensor(1.9314, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8995, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8426, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8146, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8242, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8415, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8224, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9083, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7912, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9605, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9323, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8675, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9016, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8912, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9222, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8839, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8365, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9125, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8286, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8959, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9206, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7703, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8951, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8732, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8648, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7923, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8662, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8209, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8737, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8281, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7155, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9894, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8742, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7664, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7249, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0686, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8738, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9994, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8612, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8234, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9549, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9844, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1087, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8820, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8871, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9833, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9348, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7920, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0074, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9044, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8051, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0838, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9895, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7885, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9743, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9144, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9138, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9798, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9497, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8770, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0655, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9108, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8807, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0355, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9498, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  18  Val Loss:  tensor(1.9514)  Val Accuracy:  0.14583333333333334\n",
            "tensor(1.9554, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9923, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9610, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8628, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8803, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9713, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0099, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9151, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9453, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9446, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8038, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9575, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9880, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8528, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9568, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1007, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9610, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8358, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9827, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7719, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8395, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8652, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST THE MODEL\n",
        "\n",
        "#Evaluate the accuracy on the test set.\n",
        "check_model_accuracy(model, test_loader)"
      ],
      "metadata": {
        "id": "XCtxeGkdejVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd29afb5-2640-401b-899f-f79599800af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unfreeze all layers.\n",
        "\n",
        "for i, param in enumerate(model.parameters()):\n",
        "    param.requires_grad = True \n",
        "\n",
        "#Continue Fine Tuning\n",
        "\n",
        "#init SGD optimizer & CrossEntropyLoss function\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.9 )\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#put on device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "n_epochs = 20\n",
        "step=0\n",
        "\n",
        "#Loop thru epochs \n",
        "for i in range(n_epochs):\n",
        "    val_losses = []\n",
        "    \n",
        "    #loop thru samples\n",
        "    for idx, (X, y) in enumerate(train_loader):\n",
        "        \n",
        "        X[0] = X[0].to(device)\n",
        "        X[1] = X[1].to(device)\n",
        "        masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "        masks_numbers = np.empty(masks.shape)\n",
        "        masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "        masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "        masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "        rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "        # print(X[0].shape)\n",
        "        # print(X[1].shape)\n",
        "        # print(mask.shape)\n",
        "\n",
        "        mask = masks.repeat(1,3,1,1)\n",
        "        # print(mask.shape)\n",
        "\n",
        "        # print(X[0][0].shape)\n",
        "        # print(X[1][0].shape)\n",
        "        # print(mask[0].shape)\n",
        "\n",
        "        result = np.concatenate((X[0][0].cpu().numpy(), X[1][0].cpu().numpy(), mask[0].cpu().numpy()), axis=2)\n",
        "\n",
        "        y = y.to(device)\n",
        "        \n",
        "        #make predictions\n",
        "        rgb_masks = rgb_masks.to(device)\n",
        "        preds = model(X[0], X[1], rgb_masks)\n",
        "\n",
        "        p_idx = np.argmax(preds.cpu().detach().numpy()[0], axis=0)\n",
        "        gt = str(int(y.cpu().detach()[0].item()))\n",
        "\n",
        "        #calculate loss \n",
        "        loss = loss_fn(preds.cpu(), y.cpu().to(torch.long))\n",
        "        print(loss)\n",
        "\n",
        "        #log the training loss \n",
        "        # wandb.log({\"train_loss\": loss})\n",
        "\n",
        "        #backprop\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "        #logging \n",
        "        if step%50==0:\n",
        "\n",
        "            #visualize a result from the training\n",
        "            plt.imsave(\"./training_images/epoch_\"+str(i)+\"_step_\"+str(idx)+\"_GT_\"+gt+\"_P_\"+str(p_idx)+\".jpg\", np.moveaxis(result,0,-1))\n",
        "\n",
        "            #calculate accuracy \n",
        "            model.eval()\n",
        "            val_acc=0\n",
        "            val_loss=0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch, (X, y) in enumerate(validation_loader):\n",
        "\n",
        "                    X[0] = X[0].to(device)\n",
        "                    X[1] = X[1].to(device)\n",
        "          \n",
        "                    masks = torch.unsqueeze(torch.all(torch.eq(X[0], X[1]),axis=1), axis = 1)\n",
        "\n",
        "                    masks_numbers = np.empty(masks.shape)\n",
        "                    masks_numbers[np.where(masks.cpu() == True)] = 255\n",
        "                    masks_numbers[np.where(masks.cpu() == False)] = 0\n",
        "\n",
        "                    masks_numbers_tensor = torch.from_numpy(masks_numbers.astype(np.double)).float()\n",
        "\n",
        "                    rgb_masks = masks_numbers_tensor.repeat(1,3,1,1)\n",
        "                    rgb_masks = rgb_masks.to(device)\n",
        "                    y = y.to(device)\n",
        "                    preds = model(X[0],X[1], rgb_masks)\n",
        "                    \n",
        "                    val_loss+=loss_fn(preds.cpu(), y.cpu().to(torch.long))\n",
        "                    val_acc+=accuracy(preds.cpu(), y.cpu())\n",
        "                \n",
        "                #normalize val accuracy and loss\n",
        "                val_acc = val_acc / len(validation_loader)\n",
        "                val_loss = val_loss / len(validation_loader)\n",
        "\n",
        "                #wandb.log({\"val_loss\": val_loss})\n",
        "                #wandb.log({\"val_acc\": val_acc})\n",
        "                    \n",
        "                #early stopping\n",
        "                if len(val_losses)>5:\n",
        "                    if val_loss >= (sum(val_losses[i-5:i])/5):\n",
        "                        print(\"Stopped at Epoch: \", idx)\n",
        "                        break\n",
        "\n",
        "                val_losses.append(val_loss)\n",
        "        step+=1\n",
        "\n",
        "    if len(val_losses) > 0:\n",
        "      print(\"Epoch: \", i, \" Val Loss: \", val_losses[-1], \" Val Accuracy: \", val_acc)"
      ],
      "metadata": {
        "id": "BTMggfw4l6Xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be776a26-b138-4740-9c73-9191e65bf5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8726, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9025, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8597, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9497, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9016, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0902, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9339, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0163, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8367, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9872, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9158, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9233, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9010, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7114, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0731, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9517, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7678, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0420, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9551, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8757, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7710, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7396, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  0  Val Loss:  tensor(1.9228)  Val Accuracy:  0.20833333333333334\n",
            "tensor(1.9197, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8368, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9793, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8344, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0216, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0018, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8262, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8198, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7651, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0075, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8828, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7957, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9454, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7670, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9475, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9352, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7800, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8584, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8641, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7909, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9367, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7939, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8693, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9497, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8894, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7443, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7341, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9411, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9670, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8363, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8453, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9189, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9678, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9092, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7785, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8016, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8153, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8980, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6578, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8105, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7238, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9281, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8479, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9736, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  2  Val Loss:  tensor(1.8696)  Val Accuracy:  0.25\n",
            "tensor(1.9489, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8155, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8088, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7756, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7931, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8384, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8306, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9032, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9825, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8542, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9185, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8959, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6277, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7163, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9678, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8024, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9946, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9243, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0456, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6445, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7169, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7235, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9641, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7883, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7286, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9128, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6859, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7918, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8092, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9248, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9781, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0277, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9784, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1549, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9747, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0363, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0926, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9100, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9131, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7972, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9070, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0330, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8146, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  4  Val Loss:  tensor(1.9601)  Val Accuracy:  0.1875\n",
            "tensor(1.8621, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9162, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0943, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0274, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0362, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7894, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9764, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8533, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8485, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8514, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7845, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8511, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0386, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0969, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9105, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7360, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7925, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8883, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7823, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8482, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9076, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9818, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7848, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9771, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8614, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8523, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7278, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9110, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0385, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9711, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0347, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8464, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7299, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7861, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7887, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8440, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9114, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8538, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9772, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0380, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7914, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1566, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9174, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0642, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  6  Val Loss:  tensor(1.9146)  Val Accuracy:  0.25\n",
            "tensor(1.7910, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8444, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0315, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9165, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0343, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7940, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8545, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9816, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7872, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8953, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9696, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8515, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9582, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0073, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7392, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9220, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0222, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7300, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9144, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9398, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9015, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8224, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9209, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8251, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9172, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7396, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9557, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8516, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9629, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7705, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9340, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9584, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7848, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8838, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9400, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9971, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9654, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9165, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7301, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8008, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9460, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9728, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9542, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9039, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8532, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9215, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7739, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7676, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8344, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8092, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8965, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0216, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7682, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7773, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9615, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8173, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9256, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9079, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8445, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9044, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8937, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8029, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8000, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8624, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8179, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8140, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  9  Val Loss:  tensor(1.9052)  Val Accuracy:  0.25\n",
            "tensor(1.8960, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7220, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8749, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8115, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9114, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9519, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7777, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8745, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9547, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8432, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9069, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8711, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9587, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7950, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8144, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8725, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7960, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8179, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8513, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8247, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7783, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.0410, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7574, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7691, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8289, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8760, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8253, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7525, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9599, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7996, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7973, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7836, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9738, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9129, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7154, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8165, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8730, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8729, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8711, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9281, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8192, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8464, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8045, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8750, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  11  Val Loss:  tensor(1.8360)  Val Accuracy:  0.2916666666666667\n",
            "tensor(1.8727, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7944, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7600, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8558, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8329, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8235, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8546, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8019, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7830, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8950, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8362, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8228, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7727, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8334, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7276, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9168, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7488, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8764, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9122, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7867, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9138, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8017, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8932, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9186, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7617, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8099, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8641, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7801, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8133, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8300, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8045, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7612, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7927, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7928, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7858, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8267, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8649, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8198, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8744, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8750, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8282, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8971, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8814, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7742, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  13  Val Loss:  tensor(1.8955)  Val Accuracy:  0.22916666666666666\n",
            "tensor(1.8882, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7831, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8553, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7847, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8192, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9722, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9497, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8283, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8184, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8387, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8033, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8428, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7726, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8134, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8433, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8412, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8076, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7737, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7683, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7431, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8601, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8290, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9039, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7773, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8145, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8821, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8531, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7799, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7477, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7921, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8019, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7711, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7543, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8316, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8784, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7835, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8280, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8133, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8749, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8053, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8276, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8074, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8498, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7433, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  15  Val Loss:  tensor(1.8533)  Val Accuracy:  0.22916666666666666\n",
            "tensor(1.7992, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8284, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8602, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7629, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8199, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6548, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7463, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8438, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9124, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7799, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8367, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8440, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7217, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8644, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7664, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7083, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7194, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8077, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7553, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7371, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7692, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8062, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6720, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6251, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8132, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6945, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8212, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6925, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6605, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7479, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9260, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8156, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7289, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7984, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7794, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8901, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6511, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6580, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6804, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7117, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6701, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7930, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5567, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6997, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7719, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7069, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7081, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6576, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5313, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7191, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6513, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7400, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5762, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8025, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6958, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7958, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6186, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6181, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7252, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5113, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8163, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6954, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7082, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7067, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6924, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7778, grad_fn=<NllLossBackward0>)\n",
            "Epoch:  18  Val Loss:  tensor(1.7001)  Val Accuracy:  0.5208333333333334\n",
            "tensor(1.7990, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8688, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6936, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7362, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6017, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5364, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4887, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7111, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6770, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8576, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7754, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9065, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7513, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6808, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5603, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6493, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7494, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7633, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.6635, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7773, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7205, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5823, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST THE MODEL\n",
        "\n",
        "#Evaluate the accuracy on the test set.\n",
        "accuracy, mistakes, incorrect_labels, correct_labels = check_model_accuracy(model, test_loader)"
      ],
      "metadata": {
        "id": "MVwH7AWZmQ4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "6133180b-d186-4dc5-c6ae-74b2a13b35ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-a091b34f56b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Evaluate the accuracy on the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheck_model_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-3a943e4b247d>\u001b[0m in \u001b[0;36mcheck_model_accuracy\u001b[0;34m(model, dloader)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#convert batch into variable that can have gradients applied to them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.76 GiB total capacity; 13.53 GiB already allocated; 19.75 MiB free; 13.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"./model_learning_rate_1e-3.pth\")"
      ],
      "metadata": {
        "id": "G4jgLXytuKOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel = ActionModel()\n",
        "newModel.load_state_dict(torch.load(\"./model_learning_rate_1e-3.pth\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAcgIBPEw_80",
        "outputId": "7a616d2a-89d7-423e-ac9f-7cb8c493fa7b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyDiLSP559sB",
        "outputId": "85f0c706-ff59-4975-83ce-a73cf5a443d1"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#put on device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "newModel.to(device)\n",
        "\n",
        "accuracy , correct_before, correct_after, correct_mask, correct_labels_for_correct, incorrect_before, incorrect_after, incorrect_mask, incorrect_labels, correct_labels = check_model_accuracy(newModel, test_loader)"
      ],
      "metadata": {
        "id": "Tms8RbvK49Y9"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8oNg86l65NM",
        "outputId": "44a6581e-ffd2-41ce-b22e-489363b9be40"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# let us plot the first 5 sample mistakes\n",
        "for i in range(5):\n",
        "\n",
        "  mistake_img_before = incorrect_before[i]\n",
        "  mistake_img_after = incorrect_after[i]\n",
        "  mistake_img_mask =  incorrect_mask[i]\n",
        "\n",
        "\n",
        "  result = np.concatenate((mistake_img_before, mistake_img_after, mistake_img_mask), axis=2)\n",
        "  result = np.moveaxis(result, 0, -1)\n",
        "\n",
        "  plt.imsave(\"./sample_mistakes/predicted_\" +  str(incorrect_labels[i]) + \"_correct_\"+ str(correct_labels[i]) + \".jpg\", result)\n",
        "  # plt.show()\n",
        "  print(\"PREDICTED LABEL: \" + str(incorrect_labels[i]))\n",
        "  print(\"CORRECT LABEL: \" + str(correct_labels[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inbmWDEE661o",
        "outputId": "a0c6106b-86b2-4d3d-be34-cdd4e54a1344"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREDICTED LABEL: 0\n",
            "CORRECT LABEL: 1\n",
            "PREDICTED LABEL: 4\n",
            "CORRECT LABEL: 2\n",
            "PREDICTED LABEL: 0\n",
            "CORRECT LABEL: 5\n",
            "PREDICTED LABEL: 0\n",
            "CORRECT LABEL: 2\n",
            "PREDICTED LABEL: 0\n",
            "CORRECT LABEL: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# let us plot the first 5 sample mistakes\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  correct_img_before = correct_before[i]\n",
        "  correct_img_after = correct_after[i]\n",
        "  correct_img_mask =  correct_mask[i]\n",
        "\n",
        "  result = np.concatenate((correct_img_before, correct_img_after, correct_img_mask), axis=2)\n",
        "  result = np.moveaxis(result, 0, -1)\n",
        "  print(result.shape)\n",
        "  plt.imsave(\"./sample_correct/correct_\"+ str(correct_labels_for_correct[i]) + \".jpg\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-7ep3y6Bbx9",
        "outputId": "23838f75-8eb1-44b3-e6e2-50932117108d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 1536, 3)\n",
            "(512, 1536, 3)\n",
            "(512, 1536, 3)\n",
            "(512, 1536, 3)\n",
            "(512, 1536, 3)\n"
          ]
        }
      ]
    }
  ]
}